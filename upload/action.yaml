name: S3 upload
description: Upload a set of artifacts to S3

inputs:
  # Path(s) to the artifacts to upload
  path:
    required: true
    description: Path(s) to the artifacts to upload
  # S3 url for bucket and path prefix of the artifact
  s3uri:
    required: true
    description: S3 url for bucket and path prefix of the artifact
  # Artifact key name (a unique hash or timestamp or other identifier)
  key:
    required: false
    description: Artifact key name (a unique hash or timestamp or other identifier)
    default: ${{ github.sha }}-${{ github.run_number }}-${{ github.run_attempt }}
  role-to-assume:
    required: false
    description: ARN of the role to assume. If no credentials are provided, the action will not try to authenticate with AWS and use any existing environment credentials.
  aws-access-key-id:
    required: false
    description: AWS access key ID of the S3 location. If no credentials are provided, the action will not try to authenticate with AWS and use any existing environment credentials.
  aws-secret-access-key:
    required: false
    description: AWS secret access key ID of the S3 location. If no credentials are provided, the action will not try to authenticate with AWS and use any existing environment credentials.
  aws-region:
    required: false
    description: AWS region of the S3 location
    default: us-east-1
  compress:
    required: false
    description: Whether to build a tarball of the artifacts before uploading
    default: "true"

outputs:
  s3uri:
    description: S3 URL for uploaded artifact
    value: ${{ steps.s3.outputs.s3uri }}

runs:
  using: composite
  steps:
    - name: Collect artifacts into temporary path
      id: collect
      shell: bash
      run: |
        # Create our temporary directory parent for our artifacts
        mkdir -p "$RUNNER_TEMP/actions-s3-artifact"

        # Create a unique directory for this particular action run
        TMPDIR="$(mktemp -d -p "$RUNNER_TEMP" "actions-s3-artifact/upload.XXXXXXXX")"
        echo "tmpdir=$TMPDIR" >> $GITHUB_OUTPUT
        echo "::debug::Created temporary directory $TMPDIR"

        # Assign the tarball file name for future use
        TMPTAR="$TMPDIR/artifacts.tar.gz"

        # Create a path within our temporary directory to collect all the artifacts
        TMPARTIFACT="$TMPDIR/artifacts"
        mkdir -p "$TMPARTIFACT"

        # Read the path string into a bash array for easy looping
        readarray -t ARTIFACT_PATHS <<< "${{ inputs.path }}"

        # Iterate through each artifact path and copy it to the temporary path
        for name in ${ARTIFACT_PATHS[@]}; do
          if [[ -z "$name" ]]; then
            echo "::debug::Skipping empty"
            continue
          fi
          echo "Adding '$name'"
          mkdir -p "$TMPARTIFACT/$(dirname "$name")"
          cp -r "$name" "$TMPARTIFACT/$(dirname "$name")"
        done

        # List out everything in the temporary path
        if [[ -n "$RUNNER_DEBUG" ]]; then
          echo "::debug::Contents of our temporary artifact build"
          echo "$(tree -a "$TMPDIR" 2>&1)"
        fi

        # Tarball the temporary path into a single object if "compress" is true, return the folder path otherwise
        if [[ "${{ inputs.compress }}" == "true" ]]; then
          echo "Creating artifact tarball"
          tar -czvf "$TMPTAR" -C "$TMPARTIFACT" --transform='s/^\.\///' \
            --show-transformed .

          # List the actual contents of the archive
          if [[ -n "$RUNNER_DEBUG" ]]; then
            echo "::debug::Artifact contents"
            echo "$(tar -ztvf "$TMPTAR" 2>&1)"
          fi

          # Output the compressed file keyname for use in subsequent steps
          echo "tarball=$TMPTAR" >> $GITHUB_OUTPUT
        else
          # Output the folder keyname for use in subsequent steps
          echo "folder=$TMPARTIFACT" >> $GITHUB_OUTPUT
        fi

    - name: Configure AWS credentials via OIDC
      if: inputs.role-to-assume != ''
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-skip-session-tagging: true
        role-to-assume: ${{ inputs.role-to-assume }}
        aws-region: ${{ inputs.aws-region }}

    - name: Configure AWS credentials via Access Keys
      if: inputs.role-to-assume == '' && inputs.aws-access-key-id != '' && inputs.aws-secret-access-key != ''
      uses: aws-actions/configure-aws-credentials@v3
      with:
        aws-access-key-id: ${{ inputs.aws-access-key-id }}
        aws-secret-access-key: ${{ inputs.aws-secret-access-key }}
        aws-region: ${{ inputs.aws-region }}

    - name: Upload artifact to S3
      id: s3
      shell: bash
      run: |
        AWSCMD=${AWSCMD:-aws}
        S3URI="${{ inputs.s3uri }}"
        if [[ "$S3URI" != s3://* ]]; then
          echo "::warning::'s3uri' should start with s3://"
          S3URI="s3://$S3URI"
        fi

        S3URI="${S3URI%/}/${{ inputs.key }}"
        if [[ "$S3URI" == *.tgz || "$S3URI" == *.tar.gz || "${{ inputs.compress }}" != "true" ]]; then
          echo "::debug::s3uri does not need .tgz extension, skipping"
        else
          S3URI="$S3URI.tgz"
        fi

        echo "::debug::Using AWS CLI: $AWSCMD"

        # Upload the artifact to S3 based on keyname from previous step
        if [[ "${{ inputs.compress }}" == "true" ]]; then
          echo "Uploading '${{ steps.collect.outputs.tarball }}' to S3 '$S3URI'"
          $AWSCMD s3 cp "${{ steps.collect.outputs.tarball }}" "$S3URI"
        else
          echo "Uploading '${{ steps.collect.outputs.folder }}' to S3 '$S3URI'"
          $AWSCMD s3 cp --recursive "${{ steps.collect.outputs.folder }}" "$S3URI"
        fi
        # Output the S3 URL for use in subsequent steps
        echo "s3uri=$S3URI" >> $GITHUB_OUTPUT
